import pandas as pd
import numpy as np
import joblib
import os
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.impute import SimpleImputer
from imblearn.over_sampling import SMOTE 

# --- DOSYA YOLLARI ---
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_PATH = os.path.join(BASE_DIR, 'data', 'raw', 'asthma_disease_data_fixed.csv')
MODEL_PATH = os.path.join(BASE_DIR, 'models', 'risk_tahmin_modeli.pkl')
SCALER_PATH = os.path.join(BASE_DIR, 'models', 'scaler.pkl')

def train_risk_model():
    print("\n--- LOJÄ°STÄ°K REGRESYON (OPTIMÄ°ZE EDÄ°LMÄ°Åž) ---")
    
    # 1. VERÄ° YÃœKLEME
    if not os.path.exists(DATA_PATH):
        print(f"HATA: Dosya bulunamadÄ± -> {DATA_PATH}")
        return
    
    df = pd.read_csv(DATA_PATH)
    print(f"âœ… Veri yÃ¼klendi. Hasta SayÄ±sÄ±: {len(df)}")

    # 2. HEDEF BELÄ°RLEME
    def risk_belirle(row):
        if row['Diagnosis'] == 1:
            # EÅŸik deÄŸerler
            if row['PollutionExposure'] > 5.5 or row['LungFunctionFEV1'] < 2.2:
                return 1 # YÃœKSEK RÄ°SK
            return 0 
        return 0

    df['Risk_Level'] = df.apply(risk_belirle, axis=1)

    # 3. Ã–ZELLÄ°KLER
    features = [
        'Age', 'BMI', 'Smoking', 'PhysicalActivity', 
        'PollutionExposure', 'PollenExposure', 'DustExposure', 
        'LungFunctionFEV1', 'Wheezing', 'ShortnessOfBreath',
        'FamilyHistoryAsthma'
    ]
    
    X = df[features].copy()
    y = df['Risk_Level']

    # 4. EKSÄ°K VERÄ° TAMAMLAMA
    imputer = SimpleImputer(strategy='mean')
    X_imputed = imputer.fit_transform(X)

    # 5. EÄžÄ°TÄ°M / TEST AYRIMI
    X_train, X_test, y_train, y_test = train_test_split(
        X_imputed, y, test_size=0.2, random_state=42, stratify=y
    )

    # --- SMOTE AYARI (DoÄŸruluÄŸu ArtÄ±ran KÄ±sÄ±m) ---
    # sampling_strategy=0.5 -> Riskli veriyi, saÄŸlÄ±klÄ± verinin yarÄ±sÄ± kadar Ã§oÄŸalt.
    # Bu, modeli "paranoyak" yapmadan riskleri Ã¶ÄŸretir. DoÄŸruluÄŸu artÄ±rÄ±r.
    print("Veri optimize ediliyor (SMOTE)...")
    smote = SMOTE(sampling_strategy=0.5, random_state=42)
    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

    # 6. SCALING
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train_resampled)
    X_test_scaled = scaler.transform(X_test)

    # 7. MODEL EÄžÄ°TÄ°MÄ°
    print("Model eÄŸitiliyor...")
    model = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42)
    model.fit(X_train_scaled, y_train_resampled)

    # 8. SONUÃ‡LAR
    y_pred = model.predict(X_test_scaled)
    
    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
    acc = accuracy_score(y_test, y_pred)
    risk_yakalama = tp / (tp + fn) if (tp + fn) > 0 else 0 
    
    # SADELEÅžTÄ°RÄ°LMÄ°Åž RAPOR
    print("\n" + "="*50)
    print("      ðŸ“¢ PROJE PERFORMANS RAPORU")
    print("="*50)
    print(f"âœ… GENEL DOÄžRULUK (Accuracy)       : %{acc * 100:.2f}")
    print("   (Sistemin genel baÅŸarÄ±sÄ±)")
    print("-" * 50)
    print(f"ðŸš¨ RÄ°SK YAKALAMA ORANI (Recall)    : %{risk_yakalama * 100:.2f}")
    print("   (Kriz geÃ§iren hastalarÄ± tespit etme baÅŸarÄ±sÄ±)")
    print("="*50)
    print(f"Toplam Test Edilen        : {len(y_test)}")
    print(f"GerÃ§ekten Riskli Olanlar  : {tp + fn}")
    print(f"BaÅŸarÄ±yla Tespit Edilen   : {tp}")
    print(f"GÃ¶zden KaÃ§an              : {fn}")
    print("="*50)

    # 9. KAYIT
    if not os.path.exists(os.path.dirname(MODEL_PATH)):
        os.makedirs(os.path.dirname(MODEL_PATH))
        
    joblib.dump(model, MODEL_PATH)
    joblib.dump(scaler, SCALER_PATH)
    print(f"\nðŸ’¾ Model ve Scaler kaydedildi: {MODEL_PATH}")

if __name__ == "__main__":
    train_risk_model()